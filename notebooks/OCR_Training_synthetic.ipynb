{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\selcu\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In C:\\Users\\selcu\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In C:\\Users\\selcu\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "C:\\Users\\selcu\\Anaconda3\\lib\\site-packages\\imgaug\\imgaug.py:184: DeprecationWarning: Function `Scale()` is deprecated. Use `Resize` instead. Resize has the exactly same interface as Scale.\n",
      "  warn_deprecated(msg, stacklevel=3)\n",
      "C:\\Users\\selcu\\Anaconda3\\lib\\site-packages\\imgaug\\imgaug.py:184: DeprecationWarning: Function `ContrastNormalization()` is deprecated. Use `imgaug.contrast.LinearContrast` instead.\n",
      "  warn_deprecated(msg, stacklevel=3)\n"
     ]
    }
   ],
   "source": [
    "#General Imports\n",
    "import torch\n",
    "import torch.nn  as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "#Load fake, non handwritten generator \n",
    "from ..dataset.fake_texts.pytorch_dataset_fake_2 import Dataset\n",
    "\n",
    "#Import the loss from baidu \n",
    "from torch.nn import CTCLoss\n",
    "\n",
    "#Import the model \n",
    "from ..models.fully_conv_model import cnn_attention_ocr\n",
    "\n",
    "#Helper to count params\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "#Evaluation function preds_to_integer\n",
    "from ..evaluation import wer_eval, preds_to_integer, my_collate, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up Tensorboard writer for current test\n",
    "writer = SummaryWriter(log_dir=\"/home/leander/AI/repos/OCR-CNN/logs2/correct_cosine_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3530194"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Set up model. \n",
    "cnn=cnn_attention_ocr(model_dim=64,nclasses=67,n_layers=8)\n",
    "cnn=cnn.cuda().train()\n",
    "count_parameters(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cnn=cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CTC Loss ,average_frames=True\n",
    "# ctc_loss = CTCLoss(reduction=\"mean\")\n",
    "ctc_loss = nn.CTCLoss(blank=0, reduction=\"mean\")\n",
    "#Optimizer: Good initial is 5e5 \n",
    "optimizer = optim.Adam(cnn.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We keep track of the Average loss and CER \n",
    "ave_total_loss = AverageMeter()\n",
    "CER_total= AverageMeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iter=0\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#torch.save(cnn.state_dict(), \"400ksteps_augment_new_gen_e15.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), \"415ksteps_augment_new_gen_e56.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.load_state_dict(torch.load(\"415ksteps_augment_new_gen_e56.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds=Dataset()\n",
    "trainset = DataLoader(dataset=ds,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=False,\n",
    "                      num_workers=6,\n",
    "                      pin_memory=True,\n",
    "                  \n",
    "                      collate_fn=my_collate)\n",
    "gen = iter(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs=CosineAnnealingLR(optimizer=optimizer,T_max=250000,eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start\n",
      "train start\n",
      "train start\n",
      "train start\n",
      "train start\n",
      "train start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\selcu\\PycharmProjects\\Pytorch-OCR-Fully-Convolutional\\evaluation.py:42: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return we/len(preds)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-20-cdd4e1f579af>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m             \u001B[1;31m#Then backward and step\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 31\u001B[1;33m             \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     32\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[0;32m    196\u001B[0m                 \u001B[0mproducts\u001B[0m\u001B[1;33m.\u001B[0m \u001B[0mDefaults\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    197\u001B[0m         \"\"\"\n\u001B[1;32m--> 198\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    199\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[0;32m     98\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[0;32m     99\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 100\u001B[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001B[0m\u001B[0;32m    101\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "npa=1\n",
    "\n",
    "for epochs in range(10000):\n",
    "\n",
    "    # gen = iter(trainset)\n",
    "    print(\"train start\")\n",
    "    for i, ge in enumerate(trainset):  # enumerate(ge)\n",
    "        \n",
    "        #to avoid OOM \n",
    "        if ge[0].shape[3]<=800:\n",
    "\n",
    "            #DONT FORGET THE ZERO GRAD!!!!\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Get Predictions, permuted for CTC loss \n",
    "            log_probs = cnn(ge[0].cuda()).permute((2,0,1))\n",
    "\n",
    "            #Targets have to be CPU for baidu loss \n",
    "            targets = ge[1]#.cpu()\n",
    "\n",
    "            #Get the Lengths/2 becase this is how much we downsample the width\n",
    "            input_lengths = ge[2]/2\n",
    "            target_lengths = ge[3]\n",
    "            \n",
    "            #Get the CTC Loss\n",
    "            input_len, batch_size, vocab_size = log_probs.size()\n",
    "            log_probs_lens = torch.full(size=(batch_size,), fill_value=input_len, dtype=torch.int32)\n",
    "            loss = ctc_loss(log_probs, targets, log_probs_lens, target_lengths)\n",
    "            \n",
    "            #Then backward and step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Save Loss in averagemeter and write to tensorboard \n",
    "            ave_total_loss.update(loss.data.item())\n",
    "            writer.add_scalar(\"total_loss\", ave_total_loss.average(), n_iter) \n",
    "\n",
    "\n",
    "            #Here we Calculate the Character error rate\n",
    "            cum_len=np.cumsum(target_lengths)\n",
    "            targets=np.split(ge[1].cpu(),cum_len[:-1])\n",
    "            wer_list=[]\n",
    "            for j in range(log_probs.shape[1]):\n",
    "                wer_list.append(wer_eval(log_probs[:,j,:][0:input_lengths[j],:],targets[j]))\n",
    "            \n",
    "            #Here we save an example together with its decoding and truth\n",
    "            #Only if it is positive \n",
    "            \n",
    "            if np.average(wer_list) > 0.1:\n",
    "\n",
    "                max_elem=np.argmax(wer_list)\n",
    "                max_value=np.max(wer_list)\n",
    "                max_image=ge[0][max_elem].cpu()\n",
    "                max_target=targets[max_elem]\n",
    "                \n",
    "                max_target=[ds.decode_dict[x] for x in max_target.tolist()]\n",
    "                max_target=\"\".join(max_target)\n",
    "\n",
    "                ou=preds_to_integer(log_probs[:,max_elem,:])\n",
    "                max_preds=[ds.decode_dict[x] for x in ou]\n",
    "                max_preds=\"\".join(max_preds)\n",
    "                \n",
    "                writer.add_text(\"label\",max_target,n_iter)\n",
    "                writer.add_text(\"pred\",max_preds,n_iter)\n",
    "                writer.add_image(\"img\",ge[0][max_elem].detach().cpu().numpy(),n_iter)\n",
    "                \n",
    "                #gen.close()\n",
    "                #break\n",
    "                \n",
    "            #Might become infinite \n",
    "            if np.average(wer_list)< 10: \n",
    "                CER_total.update(np.average(wer_list))\n",
    "                writer.add_scalar(\"CER\", CER_total.average(), n_iter)\n",
    "            \n",
    "            #We save when the new avereage CR is beloew the NPA\n",
    "            # npa>CER_total.average() and CER_total.average()>0 and CER_total.average()<1\n",
    "            if npa > CER_total.average() > 0 and CER_total.average()<1:\n",
    "                \n",
    "                torch.save(cnn.state_dict(), \"autosave.pt\")\n",
    "                npa=CER_total.average()\n",
    "                \n",
    "\n",
    "            n_iter=n_iter+1\n",
    "            cs.step()\n",
    "            lr=optimizer.param_groups[0][\"lr\"]\n",
    "            writer.add_scalar(\"lr\",lr,n_iter)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2.952760826470251"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CER_total.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_checkpoint({\n",
    "    'epoch': epoch + 1,\n",
    "    'arch': args.arch,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer' : optimizer.state_dict(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.load_state_dict(torch.load(\"autosave.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(torch.load(\"autosave_optimizer.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}